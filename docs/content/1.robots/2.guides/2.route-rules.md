---
title: Config Using Route Rules
description: Learn how to configure robots through route rules.
---

If you prefer, you can use route rules to configure how your routes are indexed by search engines.

You can provide the following rules:

- `{ robots: false }` - Will disable the route from being indexed using the [robotsDisabledValue](/robots/api/config#robotsdisabledvalue) config.
- `{ robots: <string> }` - Will add the provided string as the robots rule

The rules are applied using the following logic:
- `X-Robots-Tag` header - SSR only,
- `<meta name="robots">` - When using the `defineRobotMeta` or `RobotMeta` composable or component
- `/robots.txt` disallow entry - When [disallowNonIndexableRoutes](/robots/api/config#robotsdisabledvalue) is enabled

## Inline Route Rules

Requires enabling the experimental `inlineRouteRules`, see the [defineRouteRules](https://nuxt.com/docs/api/utils/define-route-rules) documentation
to learn more.

```vue
<script lang="ts" setup>
defineRouteRules({
  robots: false,
})
</script>
```

## Nuxt Config

```ts [nuxt.config.ts]
export default defineNuxtConfig({
  routeRules: {
    // use the `index` shortcut for simple rules
    '/secret/**': { robots: false },
    // add exceptions for individual routes
    '/secret/visible': { robots: true },
    // use the `robots` rule if you need finer control
    '/custom-robots': { robots: 'index, follow' },
  }
})
```
